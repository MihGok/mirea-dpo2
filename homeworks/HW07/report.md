# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 солбцов
- Признаки: id (уникальный int64), остальные - float64
- Пропуски: нет
- "Подлости" датасета: Числовые признаки в разных шкалах, различные выбросы в некоторых колонках

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 солбцов
- Признаки: id (уникальный int64), остальные - float64
- Пропуски: нет
- "Подлости" датасета: Числовые признаки в разных шкалах, различные выбросы в некоторых колонках

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 8000 строк, 4 солбцов
- Признаки: id (уникальный int64), остальные - float64
- Пропуски: нет
- "Подлости" датасета: Числовые признаки в разных шкалах, различные выбросы в некоторых колонках

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг:
    Заполнение пропусков медианой для числовых данных, StandartScaler. Для категориальных также заполнений пропусков и OneHotEncoding. После этого PCA со снижением до 2 компонент. 
- Поиск гиперпараметров:
  - Изучался k из интевала от 2 до 20, и второго метода (eps с помощью графика расстояний до соседей)
  - лучший k выбираля на основе двух графиков (инерции и коэффициента силуэта), eps с помощью графика расстояний до соседей
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz (для DBscan метрик считались только длянешуовых точек. Это быо реализовано с мпомощью mask того факта, ч класс точек шума всегда -1)
- Визуализация: PCA(2D)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- DBSCAN (`eps`, `min_samples`, доля шума)


Опционально: третий метод / дополнительные варианты параметров.

## 4. Results

Результаты представлены в файле metrics_summary.json

### 4.1 Dataset A

- Лучший метод и параметры: DBSCAN("eps":  0.075,
      "min_samples": 5)
- Метрики (silhouette / DB / CH):'silhouette': 0.7212124993378766,
                                'calinski_harabasz': 129169.8168301153,
                                'davies_bouldin': 0.3486801034700521
- Если был DBSCAN: Доля шума 2.5%
- Данное решение сочетает как хороше метрики, так и визуальную адкватность.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans(k=10)
- Метрики (silhouette / DB / CH):   'silhouette': 0.12628719497888555,
                                    'calinski_harabasz': 932.264506388584, 
                                    'davies_bouldin': 1.869849906370479
- Данное решение показывает низкие метрики, но в отличие от DBScan визуализация разбиения показывает наличие хотя бы какого то смысла, а не 1 класс и шум.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans(k=10)
- Метрики (silhouette / DB / CH):   'silhouette': 0.33519139123048636, 
                                    'calinski_harabasz': 7168.213274189978, 
                                    'davies_bouldin': 1.2031394296825058
- Данное решение показывает не самые высокие метрики, однако  другого метода он еще хуже.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
    KMeans показал плохие результаты на Dataset 1 (Silhouette 0.28) и Dataset 2 (Silhouette 0.12). KMeans ищет "шарики" (выпуклые кластеры). На Dataset 1 и 2 данные имеют сложную геометрическую форму (например, дуги, спирали или вложенные круги). Центроидный метод математически не способен описать такие структуры, поэтому он просто режет их на части прямыми линиями.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
    DBSCAN выиграл только на Dataset 1 (Silhouette 0.72). Здесь он идеально "прошел" по плотности сложной формы и отбросил шум. На Dataset 2 провалились оба. KMeans (0.12) не понял форму, а DBSCAN (0.17, по вашим данным) скорее всего либо "слил" всё в один мега-кластер (из-за слишком большого eps), либо нашел лишь один плотный кусок, посчитав всё остальное шумом. Это говорит о том, что на DS2 плотность меняется слишком сильно или кластеры соприкасаются. 
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
    Геометрия данных: На Dataset 1 это решающий фактор (KMeans там бессилен).
    Настройка eps: Провал DBSCAN на Dataset 2 (0.17) показывает, что параметр eps не был подобран идеально — алгоритм "не увидел" разрывов между кластерами.


### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали (5 запусков KMeans по разным seed или иной подход)
   Проводилась оценка стабильности KMeans через метрику ARI (Adjusted Rand Index) при многократных запусках для разного количества кластеров (K от 2 до 20).
- Что получилось (в 3-6 строк)
    При K=2 -5 наблюдается экстремально высокая устойчивость (ARI > 0.99 с минимальным отклонением  0.001). Однако, начиная с K=8 и выше, средний ARI резко падает (до 0.62 \dots 0.68), а стандартное отклонение растет (до 0.277 при $K=8).
- Вывод: устойчиво/неустойчиво и почему вы так считаете
    Модель устойчива только при малых K. Это говорит о том, что в данных есть 2–5 четко выраженных центроидных структур. При попытке заставить KMeans найти больше кластеров, результат становится случайным и сильно зависит от начальной инициализации (seed), что подтверждает неестественность дробления данных на мелкие фрагменты.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - средние Значения для центров кластеров
- 3-6 строк выводов
    Интерпретация через средние значения оказалась наиболее эффективной для KMeans, так как алгоритм работает на основе центроидов, которые по сути и являются «средним лицом» кластера.
## 6. Conclusion

-    Алгоритм под задачу: KMeans идеален для компактных групп, но беспомощен перед сложной геометрией, где лидирует DBSCAN.Иллюзия качества: Высокий Silhouette у DBSCAN может быть следствием отсечения шума; важно смотреть на noise_share.
-    ARI как детектор K: Анализ устойчивости через ARI — лучший способ выбрать число кластеров. Там, где ARI падает и растет разброс, заканчивается реальная структура данных.
-    Важность масштабирования: Без StandardScaler расчеты расстояний в DBSCAN и KMeans были бы искажены признаками с большой амплитудой.
-    Стабильность : Модель может быть очень устойчивой (как KMeans при K=2), но при этом выдавать неверное с точки зрения геометрии решение, если форма кластеров не сферическая.